#!/usr/bin/env bash
set -Eeu -o pipefail
# author: github.com/jcaillon
# description: Utility functions for the self-test script.

#===============================================================
# >>> Functions that can be used in the test scripts
#===============================================================

# Call this function to add a paragraph in the report file.
#
# $1: the text to add in the report file
#
# Usage:
#   commentTest "This is a comment."
function commentTest() {
  printf "%s\n\n" "${1:-}" >>"${_TEST_REPORT_FILE}"
}

# Call this function after each test to write the test results to the report file.
# This create a new H3 section in the report file with the test description and the exit code.
#
# $1: the title of the test
# $2: the exit code of the test
# $3: (optional) a text to explain what is being tested
#
# Usage:
#   endTest "Testing something" $?
function endTest() {
  local testTitle="${1:-}"
  local exitCode="${2:-}"
  local testDescription="${3:-}"

  resetFdRedirection

  {
    log::debug "Ended test ⌜${testTitle}⌝ with exit code ⌜${exitCode}⌝."

    # write the test title
    printf "%s\n\n" "### ${testTitle:-test}"

    # write the test description if any
    if [[ -n "${testDescription}" ]]; then
      printf "%s\n\n" "${testDescription}"
    fi

    # write the exit code
    printf "%s\n\n" "Exit code: \`${exitCode}\`"

    # write the standard output if any
    if [[ -s "${_TEST_STANDARD_OUTPUT_FILE}" ]]; then
      printf "%s\n\n%s\n" "**Standard** output:" "\`\`\`plaintext"
      echoFileSubstitutingPath "${_TEST_STANDARD_OUTPUT_FILE}"
      printf "\n%s\n\n" "\`\`\`"
    fi

    # write the error output if any
    if [[ -s "${_TEST_STANDARD_ERROR_FILE}" ]]; then
      printf "%s\n\n%s\n" "**Error** output:" "\`\`\`log"
      echoFileSubstitutingPath "${_TEST_STANDARD_ERROR_FILE}"
      printf "\n%s\n\n" "\`\`\`"
    fi

  } >>"${_TEST_REPORT_FILE}"

  # reset the standard output and error output files
  : >"${_TEST_STANDARD_OUTPUT_FILE}"
  : >"${_TEST_STANDARD_ERROR_FILE}"

  setFdRedirection

  set +Eeu +o pipefail
}

# This function allows to set the temp files and directories
# numbers so we can have consistent results.
#
# $1: the new number for temp files and directories
#
# Usage:
#   setTempFilesNumber 3
function setTempFilesNumber() {
  TEMPORARY_FILE_NUMBER=${1}
  TEMPORARY_DIRECTORY_NUMBER=${1}
}


#===============================================================
# >>> Internal tests functions
#===============================================================

function runCoreTests() {
  if [[ ! -d "${_VALET_HOME}/tests.d" ]]; then
    core::fail "The valet core tests directory ⌜${_VALET_HOME}/tests.d⌝ does not exist, can't run core tests."
  fi

  local originalUserDirectory="${VALET_USER_DIRECTORY:-}"

  # we will run some example commands so we need to set the correct user directory and commands
  export VALET_USER_DIRECTORY="${_VALET_HOME}/tests.d/0000-self-build"
  core::reloadUserCommands

  log::info "Running all test suites in directory ⌜${_VALET_HOME}/tests.d⌝."
  runTestSuites "${_VALET_HOME}/tests.d"

  VALET_USER_DIRECTORY="${originalUserDirectory}"
}

# Run all the test suites in the given directory.
# A test suite is a folder that contains a test.sh file.
# This test.sh allows to run multiple tests.
# $1: the directory containing the test suites
#
# Usage:
#   runTestSuites "${_VALET_HOME}/tests.d"
function runTestSuites() {
  local testsDirectory="${1}"

  io::createTempFile && _TEST_STANDARD_OUTPUT_FILE="${LAST_RETURNED_VALUE}"
  io::createTempFile && _TEST_STANDARD_ERROR_FILE="${LAST_RETURNED_VALUE}"
  io::createTempFile && _TEST_REPORT_FILE="${LAST_RETURNED_VALUE}"
  io::createTempFile && _TEST_TEMP_FILE="${LAST_RETURNED_VALUE}"

  local -i failedTestSuites nbTestSuites
  failedTestSuites=0
  nbTestSuites=0

  # for each test file in the test directory
  local testDirectory exitCode testDirectoryName testScript
  for testDirectory in "${testsDirectory}/"*; do
    testDirectoryName="${testDirectory##*/}"

    # skip if not a directory
    if [[ ! -d "${testDirectory}" ]]; then continue; fi

    # skip if the test directory does not match the include pattern
    if [[ -n "${INCLUDE_PATTERN:-}" && ! ("${testDirectoryName}" =~ ${INCLUDE_PATTERN}) ]]; then
      log::debug "Skipping test ⌜${testDirectoryName##*/}⌝ because it does not match the include pattern."
      continue
    fi
    # skip if the test directory matches the exclude pattern
    if [[ -n "${EXCLUDE_PATTERN:-}" && "${testDirectoryName}" =~ ${EXCLUDE_PATTERN} ]]; then
      log::debug "Skipping test ⌜${testDirectoryName##*/}⌝ because it matches the exclude pattern."
      continue
    fi

    log::info "Running test suite ⌜${testDirectory##*/}⌝."

    # write the test suite title
    printf "%s\n\n" "# Test suite ${testDirectory##*/}" >"${_TEST_REPORT_FILE}"

    # for each .sh script in the test directory, run the test
    for testScript in "${testDirectory}"/*.sh; do
      # skip if not a file
      if [[ ! -e "${testScript}" ]]; then continue; fi

      log::info "Running test       ├── ⌜${testScript##*/}⌝."

      runTest "${testDirectory}" "${testScript}"
    done

    exitCode=0
    compareWithApproved "${testDirectory}" "${_TEST_REPORT_FILE}" || exitCode=$?
    nbTestSuites+=1

    if [[ "${exitCode}" -eq 0 ]]; then
      log::success "Test suite ${testDirectory##*/} passed."
    else
      log::warning "Test suite ${testDirectory##*/} failed."
      failedTestSuites+=1
    fi
  done

  if [[ failedTestSuites -gt 0 ]]; then
    local failMessage
    failMessage="A total of ⌜${failedTestSuites}⌝/⌜${nbTestSuites}⌝ test(s) failed."
    if [[ ${AUTO_APPROVE:-false} == "true" ]]; then
      failMessage+=$'\n'"The received test result files were automatically approved."
      log::warning "${failMessage}"
    else
      failMessage+=$'\n'"You should review the difference in the logs above or by comparing each ⌜**.received.md⌝ files with ⌜**.approved.md⌝ files."
      failMessage+=$'\n'"If the differences are legitimate, then approve the changes by running this command again with the option ⌜-a⌝."
      core::fail "${failMessage}"
    fi
  elif [[ nbTestSuites -gt 0 ]]; then
    log::success "A total of ⌜${nbTestSuites}⌝ tests passed!"
  else
    log::warning "No tests were found."
  fi

}

function runTest() {
  local testDirectory="${1}"
  local testScript="${2}"

  # redirect the standard output and error output to files
  setFdRedirection

  # make sure that, if we exit in the test, we catch that and explain to the user
  # why this should not happen
  eval "function onExitTest() { onExitTestInternal; }"

  # used in echoFileSubstitutingPath to replace this path with .
  CURRENT_DIRECTORY="${PWD}"

  # write the test script name
  local scriptName="${testScript##*/}"
  scriptName="${scriptName%.sh}"
  printf "%s\n\n" "## Test script ${scriptName}" >>"${_TEST_REPORT_FILE}"

  # run the test
  pushd "${testDirectory}" >/dev/null
  # shellcheck disable=SC1091
  set +Eeu +o pipefail
  # shellcheck disable=SC1090
  source "${testScript}"
  set -Eeu -o pipefail
  popd >/dev/null

  # remove the onExitTest function, we can exit safely now
  unset -f onExitTest

  resetFdRedirection

  # test if the user forgot to call endTest
  if [[ -s "${_TEST_STANDARD_OUTPUT_FILE}" || -s "${_TEST_STANDARD_ERROR_FILE}" ]]; then
    core::fail "The test script ⌜${testScript}⌝ did not call endTest OR it had outputs after the last endTest call."
  fi

}

function compareWithApproved() {
  local testDirectory exitCode approvedFile receivedFile receivedFileToCopy
  testDirectory="${1}"
  receivedFileToCopy="${2}"
  testName="${testDirectory##*/}"

  approvedFile="${testDirectory}/results.approved.md"
  receivedFile="${testDirectory}/results.received.md"

  if [[ ! -f "${approvedFile}" ]]; then
    log::debug "🧪 ${testName}: no approved file, creating one."
    : >"${approvedFile}"
  fi

  if diff --color -u "${approvedFile}" "${receivedFileToCopy}" 1>&2; then
    log::debug "🧪 ${testName}: OK, equal to approved file."
    rm -f "${receivedFile}" 2>/dev/null || true
    return 0
  else
    echo "${receivedFile} is different than ${approvedFile} (see above)" 1>&2
    log::warning "🧪 ${testName}: KO, differs from approved file (see difference above)." | tee >(cat >&2)
  fi

  # if the option is activated, we approve the received file
  if [[ ${AUTO_APPROVE:-false} == "true" ]]; then
    log::info "🧪 ${testName}: Auto-approving"
    cp -f "${receivedFileToCopy}" "${approvedFile}"
    rm -f "${receivedFile}" 2>/dev/null || true
  else
    cp -f "${receivedFileToCopy}" "${receivedFile}"
  fi

  return 1
}

# Allows to explicitly warn the user that a test made Valet exit (it should not).
# Give guidance on what to do to fix this.
function onExitTestInternal() {
  local rc=$?

  resetFdRedirection

  source io

  local message="The program has exit during a test with code ${rc}."$'\n'
  io::readFile "${_TEST_STANDARD_ERROR_FILE}"
  message+="Current test error output:"$'\n'"⌜${LAST_RETURNED_VALUE}⌝"$'\n'
  message+="If you expect the tested function/program to exit/fail, then run it in a subshell like that:"$'\n'"(myFunctionThatFails)"

  log::error "${message}"

  ERROR_DISPLAYED=1
}

# After this function call, everything written to stdout and stderr will be redirected
# to the test output files.
# Call resetFdRedirection to reset the redirection.
function setFdRedirection() {
  # redirect the standard output and error output to files
  exec 3>&1 1>"${_TEST_STANDARD_OUTPUT_FILE}"
  exec 4>&2 2>"${_TEST_STANDARD_ERROR_FILE}"

  # sets up a simpler log function for the tests
  # so we can have consistent results independent of the environment
  if [[ -z "${ORIGINAL_LOG_LINE_FUNCTION:-}" ]]; then
    ORIGINAL_LOG_LINE_FUNCTION="${LOG_LINE_FUNCTION}"
    ORIGINAL_VALET_CONFIG_DISABLE_COLORS="${VALET_CONFIG_DISABLE_COLORS:-}"
    ORIGINAL_LOG_LEVEL="${VALET_LOG_LEVEL:-}"
    ORIGINAL_VALET_CONFIG_DISABLE_LOCAL_BIN="${VALET_CONFIG_DISABLE_LOCAL_BIN:-}"
  fi
  export VALET_LOG_LEVEL="info"
  log::setLevel info &>/dev/null
  export VALET_CONFIG_DISABLE_COLORS="true"
  log::setColors
  export VALET_CONFIG_DISABLE_LOG_TIMESTAMP="true"
  export VALET_CONFIG_DISABLE_NERDFONT_ICONS="true"
  export VALET_CONFIG_DISABLE_LOG_WRAP="true"
  export VALET_CONFIG_ENABLE_CI_MODE="false"
  export VALET_CONFIG_LOG_COLUMNS=9999
  export _COLUMNS=9999
  export VALET_CONFIG_DISABLE_LOCAL_BIN="true"
  if [[ -z "${SIMPLIFIED_LOG_LINE_FUNCTION:-}" ]]; then
    log::createPrintFunction
    SIMPLIFIED_LOG_LINE_FUNCTION="${LOG_LINE_FUNCTION}"
  fi
  eval "${SIMPLIFIED_LOG_LINE_FUNCTION}"
}

# Restores the standard output and error output.
# Call this function after setFdRedirection.
function resetFdRedirection() {
  # reset the standard output and error output
  exec 1>&3 3>&-
  exec 2>&4 4>&-

  # reset the original logs
  export VALET_LOG_LEVEL="${ORIGINAL_LOG_LEVEL}"
  log::setLevel "${ORIGINAL_LOG_LEVEL}" &>/dev/null
  export VALET_CONFIG_DISABLE_COLORS="${ORIGINAL_VALET_CONFIG_DISABLE_COLORS}"
  export VALET_CONFIG_DISABLE_LOCAL_BIN="${ORIGINAL_VALET_CONFIG_DISABLE_LOCAL_BIN}"
  log::setColors
  eval "${ORIGINAL_LOG_LINE_FUNCTION}"
}

function setGlobalOptions() {
  unset AUTO_APPROVE INCLUDE_PATTERN EXCLUDE_PATTERN
  if [[ -n "${autoApprove:-}" ]]; then
    AUTO_APPROVE="true"
  fi
  if [[ -n "${include:-}" ]]; then
    log::info "Including only test suites that match the pattern ⌜${include}⌝."
    INCLUDE_PATTERN="${include}"
  fi
  if [[ -n "${exclude:-}" ]]; then
    log::info "Excluding all test suites that match the pattern ⌜${exclude}⌝."
    EXCLUDE_PATTERN="${exclude}"
  fi
}

# This function is used to echo the content of a file with some substitutions.
# The substitutions are:
# - replace the _VALET_HOME with $_VALET_HOME
# - replace the current test directory with a dot
# - replace a line with ${TMPDIR}/valet-*/ (temp directory) by /valet/
#
# This allows to have consistent results accross different execution environments for the tests.
#
# Usage:
#   myCommandThatProducesLinesWithValetDirectoryPath 2> "${_TEST_TEMP_FILE}"
#   echoFileSubstitutingPath "${_TEST_TEMP_FILE}" 1>&2
function echoFileSubstitutingPath() {
  local file="${1}"
  local line
  local IFS=$'\n'
  local -i firstLine=1
  while read -rd $'\n' line; do
    if [[ firstLine -eq 1 ]]; then
      firstLine=0
    else
      echo
    fi
    line="${line//${_VALET_HOME}/\$_VALET_HOME}"
    line="${line//${CURRENT_DIRECTORY}/.}"
    line="${line//${_TEMPORARY_PREFIX}*.valet/\/tmp/valet}"
    line="${line//${_TEMPORARY_IN_MEM_PREFIX}*.valet/\/tmp/valet}"
    if [[ ${line} =~ "after "[0-9]{1,}s.$ ]]; then
      line="${line/%after */after Xs.}"
    fi
    echo -n "${line}"
  done <"${file}"
}